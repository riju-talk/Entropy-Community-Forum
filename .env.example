# Monorepo root environment file (shared by all apps)
# Copy to .env and fill values. This single file is loaded by both the web app and the AI agent.

# ===== Database =====
DATABASE_URL=
# If using Vercel/Neon, you may instead use one of these (prefer a single source of truth):
# POSTGRES_PRISMA_URL=
# POSTGRES_URL=
# POSTGRES_URL_NON_POOLING=

# ===== NextAuth =====
NEXTAUTH_SECRET=
# NEXTAUTH_URL=

# ===== Firebase (Client; exposed on client via NEXT_PUBLIC_*) =====
NEXT_PUBLIC_FIREBASE_API_KEY=
NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=
NEXT_PUBLIC_FIREBASE_PROJECT_ID=
NEXT_PUBLIC_FIREBASE_APP_ID=
NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID=
NEXT_PUBLIC_FIREBASE_MEASUREMENT_ID=

# ===== Firebase Admin (Server-side only) =====
FIREBASE_ADMIN_PROJECT_ID=
FIREBASE_ADMIN_CLIENT_EMAIL=
FIREBASE_ADMIN_PRIVATE_KEY=

# ===== Athena / AI Agent Backend =====
AI_BACKEND_URL=http://localhost:3000
AI_BACKEND_TOKEN=

# ===== Stripe (optional) =====
STRIPE_SECRET_KEY=
NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=
STRIPE_WEBHOOK_SECRET=

# ===== Email / SMTP (optional) =====
SMTP_HOST=
SMTP_PORT=
SMTP_USER=
SMTP_PASS=

# ===== Supabase (optional) =====
SUPABASE_URL=
SUPABASE_ANON_KEY=
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
SUPABASE_SERVICE_ROLE_KEY=

# ===== AI Agent specific =====
OPENAI_API_KEY=
LLM_MODEL=gpt-3.5-turbo
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1000
EMBEDDING_MODEL=all-MiniLM-L6-v2
# Data directories used by AI agent (paths are inside the container when dockerized)
CHROMA_PERSIST_DIR=./data/chroma_db
UPLOAD_DIR=./data/uploads
MAX_UPLOAD_SIZE=10485760
ALLOWED_FILE_TYPES=.pdf,.txt

# ===== CORS =====
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# ===== Misc =====
RATE_LIMIT_PER_MINUTE=30
DEBUG=false
