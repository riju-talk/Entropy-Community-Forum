version: '3.8'

services:
  nextjs:
    env_file: ./.env
    build:
      context: ./apps/app
      dockerfile: Dockerfile
    ports:
      # The Next app runs on port 5000 in package.json dev script
      - "5000:5000"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - NEXTAUTH_URL=${NEXTAUTH_URL}
      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET}
      - GITHUB_ID=${GITHUB_CLIENT_ID}
      - GITHUB_SECRET=${GITHUB_CLIENT_SECRET}
      - FIREBASE_API_KEY=${FIREBASE_API_KEY}
      - NEXT_PUBLIC_FIREBASE_PROJECT_ID=${NEXT_PUBLIC_FIREBASE_PROJECT_ID}
      - FIREBASE_AUTH_DOMAIN=${FIREBASE_AUTH_DOMAIN}
      - AI_BACKEND_URL=http://ai-agent:8000
      - AI_BACKEND_TOKEN=${NEXT_PUBLIC_AI_BACKEND_TOKEN}
    depends_on:
      - db
      - ai-agent
    volumes:
      - ./apps/app:/app
      - /app/node_modules
      - /app/.next
    restart: unless-stopped

  ai-agent:
    env_file: ./.env
    build:
      context: ./apps/ai-agent
      dockerfile: Dockerfile.dev
    volumes:
      - ./apps/ai-agent:/app
      - ai_agent_data:/app/data
    ports:
      - "8000:8000"
    environment:
      - AI_BACKEND_TOKEN=${NEXT_PUBLIC_AI_BACKEND_TOKEN}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - DEBUG=true
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS}
      - CHROMA_PERSIST_DIR=/app/data/chroma_db
      - UPLOAD_DIR=/app/data/uploads
      - LLM_MODEL=${LLM_MODEL}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

volumes:
  postgres_data:
  ai_agent_data:
